{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (0, 0), output: 0\n",
      "input: (1, 0), output: 1\n",
      "input: (0, 1), output: 1\n",
      "input: (1, 1), output: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w11 = np.array([-2,-2])\n",
    "w12 = np.array([2,2])\n",
    "w2 = np.array([1,1])\n",
    "b1 = 3\n",
    "b2 = -1\n",
    "b3 = -1\n",
    "\n",
    "def MLP(x,w,b):\n",
    "    y = np.sum(w*x)+b\n",
    "    if y <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def NAND(x1,x2):\n",
    "    return MLP(np.array([x1,x2]),w11,b1)\n",
    "\n",
    "def OR(x1,x2):\n",
    "    return MLP(np.array([x1,x2]),w12,b2)\n",
    "\n",
    "def AND(x1,x2):\n",
    "    return MLP(np.array([x1,x2]),w2,b3)\n",
    "\n",
    "def XOR(x1,x2):\n",
    "    return AND(NAND(x1,x2),OR(x1,x2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for x in [(0,0),(1,0),(0,1),(1,1)]:\n",
    "        y = XOR(x[0],x[1])\n",
    "        print(\"input: {}, output: {}\".format(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back propagation -> for multi perceptron with many layers\n",
    "there is vanishing gradient problem (due to sigmoid activation function)\n",
    "that's where deep learning is introduced. (changed activation func)\n",
    "\n",
    "hyperblic  tangent -> tanh (has negative value problem)\n",
    "#Relu function is popular (made deep learning popular)-> softplus function is popiar\n",
    "\n",
    "final output layer uses sigmoid, hidden layer use relu, and softplus\n",
    "\n",
    "thesedays Adam is the best gradient descent method. \n",
    "\n",
    "sigmoid function is the most accurate when there are two options to choose from\n",
    "\n",
    "hyper parameters -> things chosen by human. (like layer number)\n",
    "\n",
    "model -> the NN that is made after learning with the data (all appropriate weights)\n",
    "\n",
    "use python library called pandas to visualise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
